
# Spark Engine ID  -> Update with Engine ID provided by instructor
SPARK_ENGINE_ID=""

# cloud user id / Update with your IBMID, usually your email
CLOUD_USER_ID = ""

# COS buckets -> Update with COS bucket names provided by instructor
HIVE_BUCKET=""
WXD_BUCKET=""
MILVUS_BUCKET=""
INPUT_BUCKET=""

# watsonx data catalogs -> Should not need to change unless provided by instructor
HIVE_CATALOG="hive_catalog"
ICEBERG_CATALOG="iceberg_data"


# watsonx.data schemas -> Update schemas names to add your name and first 3 letter from surname
SCHEMA_DWH_OFFLOAD = "netezza_offload_YourName_First3LettersOfSurname"
SCHEMA_DATA_H = "input_data_hive_YourName_First3LettersOfSurname"
SCHEMA_DATA_I = "clients_schema_YourName_First3LettersOfSurname"


# watsonx.ai ->  Copy from your Reference Note
WATSONX_URL = ""
WATSONX_PROJECT_ID = ""
WATSONX_DEPLOYMENT_SPACE_ID = ""

# milvus ingestion parameters ->> Update collection name to add your name and first 3 letter from surname
MV_COLLECTION_NAME="equity_research_YourName_First3LettersOfSurname"

# COS folder with input pdf files for milvus ingestion -> Should not need to change unless provided by instructor
COS_FOLDER = "pdfs"

# parameters for milvus ingestion -> Should not need to change 
SIMILARITY_METRIC="L2"
SENTENCE_TRANSFORMER = "sentence-transformers/all-MiniLM-L6-v2"
TEXT_SPLITTER_CHUNK_SIZE=1000
TEXT_SPLITTER_CHUNK_OVERLAP=200
TEXT_SPLITTER_SEPARATORS='[" \n", "\n"]'
TEXT_REPLACEMENTS='{"âœ”": "ok"}'
TEXT_SPLITTER_TYPE="RecursiveCharacterTextSplitter"